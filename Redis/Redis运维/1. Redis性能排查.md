## 1. Redis真的变慢了吗？

调用Redis的链路耗时变长了，可能有2个原因

* 业务服务器与Redis服务器之间的网络存在问题
* Redis本身存在问题

要确定具体原因，需要对Redis做基准性能测试，判断Redis性能是否真的变慢了

## 2. 寻找耗时的命令

1. 查询Redis的慢日志，看看哪些命令耗时长
   * O(N)以上复杂度的命令——变慢的原因在于时间复杂度搞，需要更多的CPU资源
   * O(N)复杂度的命令，N值很大——网络传输耗时大
2. 从资源使用率来分析
   * 如果Redis的CPU使用率很高，可能是复杂度过高的命令导致
   * 如果Redis响应延迟过长，可能是上述两种指令导致
3. 如何解决问题
   * 尽量不要使用O(N)以上复杂度过高的命令，对于数据的聚合操作，放在业务做
   * 执行O(N)命令时候，N尽可能小(N<=300)

## 3. bigkey

* 如果在慢查询日志中，SEL/DEL这种简单的命令出现在慢查询日志中——可能是对bigkey的操作

* Redis写入bigkey时，分配内存比较耗时，在删除bigkey时，释放内存也比较耗时

* 业务代码要避免写入一个bigkey

* Redis6.0——开启lazy-free机制，将DEL放在后台执行

## 4. 集中过期

* 如果你发现，平时在操作 Redis 时，并没有延迟很大的情况发生，但在某个时间点突然出现一波延时，其现象表现为：**变慢的时间点很有规律，例如某个整点，或者每间隔多久就会发生一波延迟**
  
  如果是这种情况——可能是大量的key集中过期

* Redis有个定时任务来删除过期的key
  
  如果定时任务在执行的时候，出现了大量key过期，那么应用程序访问Redis时，必须等待这个定时任务结束——导致延时变大
  
  如果过期的key中有bigkey，耗时会更久

* **解决方案**
  
  * 集中过期key加入一个随机过期时间，将过期时间打散
  * 开启lazy-free，将删除放在后台执行

## 5. 实例内存达到上限

如果Redis实例设置了内存上限maxmemory，可能导致Redis变慢

当Redis内存达到maxmemory后，每次写入新的数据，Redis都必须先从实例中剔除一部分数据，这个逻辑在**命令真正执行之前执行**——会增加操作Redis的延迟

* **建议**
  1. 避免存储bigkey，降低释放内存的耗时
  2. 淘汰策略采用随机淘汰（快）
  3. 拆分实例
  4. 使用lazy-free

## 6. fork耗时严重

fork会消耗大量的CPU资源，并且在fork完成之前，整个Redis实例会被阻塞住，无法处理任何客户端请求

通过info命令查看latest_fork_usec可以查看fork耗时

* **建议**
  1. 控制 Redis 实例的内存：尽量在 10G 以下，执行 fork 的耗时与实例大小有关，实例越大，耗时越久
  2. 合理配置数据持久化策略：在 slave 节点执行 RDB 备份，推荐在低峰期执行，而对于丢失数据不敏感的业务（例如把 Redis 当做纯缓存使用），可以关闭 AOF 和 AOF rewrite
  3. Redis 实例不要部署在虚拟机上：fork 的耗时也与系统也有关，虚拟机比物理机耗时更久
  4. 降低主从库全量同步的概率：适当调大 repl-backlog-size 参数，避免主从全量同步（全量同步中master会重新生成RDB文件）

## 7. 操作系统开启了内存大页

* 应用程序向操作系统申请内存时，是按**内存页**进行申请的，而常规的内存页大小是 4KB
* Linux 内核从 2.6.38 开始，支持了**内存大页机制**，该机制允许应用程序以 2MB 大小为单位，向操作系统申请内存

fork操作后，父进程与子进程通过copy-on-write机制共享相同的物理内存，如果父进程在此期间需要进行写操作，会创建一个副本，将数据拷贝到副本上，在副本上写

如果开启了内存大页，那么Redis在申请副本时，以2MB为单位申请内存，申请内存耗时变长，影响性能

**不建议在运行Redis的服务器上开启内存大页**

## 8. 开启AOF

AOF在everysec模式下，在磁盘负载大的情况下，仍可能导致Redis延迟变大，甚至阻塞——everysec策略下的AOF追加阻塞

* 需要排查磁盘负载很大的原因
  * 有个子进程正在执行AOF rewrite，占用大量磁盘资源
    * 解决方法——配置 **no-appendfsync-on-rewrite yes**：在AOF rewrite时，AOF进程不能进行刷盘，但是开启这个配置后，如果发生Redis宕机，可能会丢失更多的数据
  * 有其他进程正在执行大量的写文件操作
    * 解决方法——迁移应用

## 9. 绑定CPU

很多时候，我们在部署服务时，为了提高服务性能，降低应用程序在多个 CPU 核心之间的上下文切换带来的性能损耗，通常采用的方案是**进程绑定 CPU** 的方式提高性能

Redis除了主线程外，还会创建子进程，子线程

如果Redis进程只绑定了一个逻辑核心，子进程会继承父进程的CPU使用偏好，导致子进程与父进程争夺CPU资源

* **解决方法**
  
  * Redis绑定多个逻辑核心，这多个逻辑核心最好共用一个物理核心（但这种情况下，子进程和子线程还是会在多个逻辑核心上进行切换，上下文切换会带来性能损耗）
  
  * 进一步解决——让各个进程线程绑定**固定**的逻辑核心
    
    ```SHELL
    # Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6
    server_cpulist 0-7:2
    
    # 后台子线程绑定到 CPU核心 1,3
    bio_cpulist 1,3
    
    # 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11
    aof_rewrite_cpulist 8-11
    
    # 后台 RDB 进程绑定到 CPU 核心 1,10,11
    # bgsave_cpulist 1,10-1
    ```

## 10. 使用Swap

* 如果你发现 Redis 突然变得非常慢，**每次的操作耗时都达到了几百毫秒甚至秒级**，那此时你就需要检查 Redis 是否使用到了 Swap，在这种情况下 Redis 基本上已经无法提供高性能的服务了

* Swap：操作系统为了缓解内存不足对应用程序的影响，允许把一部分内存中的数据换到磁盘上，这些内存数据被换到磁盘上的区域，就是 Swap

* Redis访问swap上的数据时，是从磁盘读取的，非常慢

* 解决方案
  
  * 增加机器内存
  * 禁用swap

## 11. 碎片整理

* Redis4.0以下，只能通过重启实例来整理内存碎片
* Redis4.0，提供自动碎片整理的功能，可以配置开启碎片自动整理，但是Redis的碎片整理在主线程执行，会导致延迟增加

```shell
# 开启自动内存碎片整理（总开关）
activedefrag yes

# 内存使用 100MB 以下，不进行碎片整理
active-defrag-ignore-bytes 100mb

# 内存碎片率超过 10%，开始碎片整理
active-defrag-threshold-lower 10
# 内存碎片率超过 100%，尽最大努力碎片整理
active-defrag-threshold-upper 100

# 内存碎片整理占用 CPU 资源最小百分比
active-defrag-cycle-min 1
# 内存碎片整理占用 CPU 资源最大百分比
active-defrag-cycle-max 25

# 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量
active-defrag-max-scan-fields 1000
```
