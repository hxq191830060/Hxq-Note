## 1. Redis实现分布式锁

**上锁**和 **释放锁**都必须保证是 **原子操作**

### 1.1 上锁

> set lock_key  unique_value  [EX seconds|PX milliseconds]  NX
> 
> * 创建成功就是取得锁
> 
> * 设置过期时间——防止客户端上完锁后发生异常造成死锁
> 
> * NX——只有key不存在才能创建成功，只有锁没有被其他线程获取才能尝试获得锁
> 
> * unique_value为获得锁的客户端的唯一标识——区分不同的客户端，防止锁被其他客户端误删

### 1.2 释放锁

* 释放锁时，客户端要检查锁的value是否为自己的唯一标识，是的话才能释放锁（防止误删别人的锁）

整个逻辑必须是**原子操作**，我们使用**Lua脚本**来实现

```lua
if redis.call("get",KEYS[1])==ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

### 1.3 优缺点

* **优点**
  
  * 性能高效
  
  * 实现方便

* 缺点
  
  * **分布式锁超时消失**，如果超时时间过短，会导致锁自动消失，导致导致多个应用服务同时取得锁
  
  * **分布式锁不可靠**，Redis主从复制是异步的，这会导致主从节点之间的数据不一致，如果Client在主节点成功加锁，锁数据还没同步到从节点，此时主节点宕机了，新晋升的新主中是没有这个锁的，其他客户端就可以再新主上再次获得这个锁，导致多个应用服务同时取得锁



## 2. 解决分布式锁超时消失

1. 为过期时间设置一个合理的值（预防）

2. 守护线程——另外起一个线程，定期检查锁的失效时间，如果锁快要过期了，但是操作还没有执行完，那么自动为锁续命（Redission实现方案）

> Redisson 里面就实现了这个方案，使用“看门狗”定期检查（每1/3的锁时间检查1次），如果线程还持有锁，则刷新过期时间。

3. 超时回滚——线程获得锁后执行任务耗时过长导致锁自动消失了，那么线程在删除锁时会发现锁已经被其他线程获取了，那么此时执行的操作是不安全的，需要进行回滚，并返回失败



## 3. 分布式锁不可靠

* 守护线程仍然无法解决**分布式锁不可靠的问题**，分布式锁不可靠的本质原因——主从复制是异步的，导致主从节点之间的数据不一致，所以解决方向就是保证数据一致，主流的解决方案有两种
  
  * **RedLock**
  
  * **Zookeeper**



## 4. RedLock

RedLock中对Redis实例加锁和解锁跟上面讲的是一样的

假设我们有 N 个 Redis 主节点，例如 N = 5（至少5个实例），这些节点是完全独立的（不是Redis Cluster），为了取到锁，客户端应该执行以下操作:

1. 获取当前时间

2. 客户端按顺序依次向N个Redis实例发送加锁命令（加锁操作要设置超时时间，如果一个Redis实例不可用，超时放弃，尽快去尝试下一个Redis实例）

3. 一旦客户端对N个Redis实例都发送完加锁操作，客户端会计算整个加锁过程的耗时，只有满足以下2个条件才会认为加锁成功
   
   * 客户端从超过半数(>=N/2+1)的Redis实例上成功获得锁
   * 整个加锁过程的耗时<锁的有效时间

4. 如果加锁成功——重新计算锁的有效时间（初始有效时间-加锁过程的耗时）
   
   如果加锁失败——客户端在所有Redis实例上发送解锁命令
   
   如果加锁成功，但是锁新的有效时间已经来不及完成共享数据的操作——客户端在所有Redis实例上发送解锁命令

该方案看着挺美好的，但是实际上我所了解到的在实际生产上应用的不多，主要有两个原因：1）该方案的成本似乎有点高，需要使用5个实例；2）该方案一样存在问题。

该方案主要存以下问题：

1. **严重依赖系统时钟**。如果线程1从3个实例获取到了锁，但是这3个实例中的某个实例的系统时间走的稍微快一点，则它持有的锁会提前过期被释放，当他释放后，此时又有3个实例是空闲的，则线程2也可以获取到锁，则可能出现两个线程同时持有锁了。
2. **分布式锁过期问题**，如果线程1成功获得锁后，因为GC阻塞或者业务逻辑耗时过长，导致锁失效了，线程2也可以获得锁，导致多个线程同时操作共享资源
