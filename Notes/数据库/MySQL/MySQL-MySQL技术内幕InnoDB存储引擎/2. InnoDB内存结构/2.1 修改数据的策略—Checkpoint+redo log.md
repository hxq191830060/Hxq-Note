**修改数据的策略**

* **第一版的思路**

  在缓冲池的LRU列表中修改页，使之成为脏页，并将脏页复制到Flush列表上

  修改缓冲区的LRU列表中的页，然后复制页到Flush列表，将Flush列表中的脏页刷新到磁盘上

  * 问题：脏页还未刷新到磁盘上时，数据库宕机，会造成数据丢失

* **第二版思路**

  采用**Write Ahead Log**策略

  事务commit时

  ①先把更新操作写入redo log buffer，然后redo log buffer按照一定规则将更新操作刷新到磁盘上的redo log file中

  ②写好事务后，修改缓冲池中的页，并复制到Flush列表，然后找到一定的时机将Flush列表中的脏页刷新到磁盘上

  * **问题**：什么时机把脏页刷新到磁盘上？

    * **每次更新操作，只写redo log file，并修改缓冲池中页，不把脏页刷新到磁盘**

      这种方法是可以的，提高的效率，同时如果数据库宕机也可以根据磁盘上的redo log file进行数据恢复

      但问题是——redo log file过大，数据库恢复需要的时间过长

    * **每次修改一次缓存区的页，就把脏页刷新到磁盘上**

      问题：效率低下

  * 基于这个问题，我们采用**Checkpoint**机制



* **实际采用的思路——Checkpoint+redo log**

  事务commit时

  ①先把更新操作写入redo log buffer，然后redo log buffer按照一定规则将更新操作刷新到磁盘上的redo log file中

  ②写好事务后，修改缓冲池中的页，并把脏页复制到Flush列表，当触发**Checkpoint**时，对Flush列表进行**Checkpoint操作**

  Checkpoint做两件事

  * 将缓冲池中的Flush列表的脏页刷新到磁盘上

  * 让磁盘的redo log file中，Checkpoint之前的页的log标记为无效

    （redo log file是循环写入，循环使用的。一方面，redo log file中的无效log可以被覆盖，这样就可以保证redo file log不会过大，可以循环使用。另一方面，如果数据库发生宕机，我们恢复数据库不需要重做全部的log，因为Checkpoint之前的页都已经刷新到磁盘了，只需要对redo log file中Checkpoint后的log进行恢复即可）

  